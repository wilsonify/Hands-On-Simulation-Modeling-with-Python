"""
Simulating airfoil self-noise using ANNs

The noise generated by an airfoil is due to the interaction between a
turbulent airflow and the aircraft's airfoil blades.

Predicting the acoustic field in these situations requires an
aeroacoustics methodology that can operate in complex environments.

Additionally, the method that is used must avoid the formulation of coarse hypotheses regarding geometry,
compactness, and the content of the frequency of sound sources.

The prediction of the sound generated by a turbulent flow must, therefore, correctly model both the
physical phenomena of sound propagation and the turbulence of the flow.

Since these two phenomena manifest energy and scales of very different lengths,
the correct prediction of the sound generated by a turbulent flow is not easy to model.


Aircraft noise is a crucial topic for the aerospace industry.

The NASA Langley Research Center has funded several strands of research to effectively
study the various mechanisms of self-noise airfoil.

Interest was motivated by its importance for broadband helicopter rotors,
wind turbines, and cell noises.

The goal of these studies then focused on the challenge of reducing
external noises generated by the entire cell of an aircraft by 10 decibels.

In this example, we will elaborate on a model based on ANNs to predict
self-noise airfoil from a series of airfoil data measured in a wind tunnel.

Important note
The dataset we will use was developed by NASA in 1989 and is available on the UCI Machine Learning Repository site.
The UCI Machine Learning Repository is available at https://archive.ics.uci.edu/ml/datasets/

Airfoil+Self-Noise .
The dataset was built using the results of a series of
aerodynamic and acoustic tests on sections of aerodynamic blades performed in an anechoic wind tunnel.

The following list shows the features of the dataset:
• Number of instances: 1,503
• Number of attributes: 6
• Dataset characteristics: Multivariate
• Attribute characteristics: Real
• Dataset date: 2014-03-04

The following list presents a brief description of the attributes:
• Frequency : Frequency in Hertz (Hz)
• AngleAttack : Angle of attack in degrees
• ChordLength : Chord length in meters
• FSVelox : Free-stream velocity in meters per second
• SSDT : Suction-side displacement thickness (SSDT) in meters
• SSP : Scaled sound pressure level in decibels246


In the six attributes we have listed, the first five represent the predictors,
and the last one represents the response of the system that we want to simulate.

It is, therefore, a regression problem because the answer has continuous values.
In fact, it represents the self-noise airfoil, in decibels, measured in the wind tunnel.
"""

import pandas as pd
from sklearn.preprocessing import MinMaxScaler
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.neural_network import MLPRegressor

ASNNames = ['Frequency', 'AngleAttack', 'ChordLength', 'FSVelox', 'SSDT', 'SSP']


def read_ASNData():
    ASNData = pd.read_csv('airfoil_self_noise.dat', delim_whitespace=True, names=ASNNames)
    print(ASNData.head(20))
    print(ASNData.info())
    return ASNData


def compute_ASNDataScaled(ASNData):
    ScalerObject = MinMaxScaler()
    print(ScalerObject.fit(ASNData))
    ASNDataScaled = ScalerObject.fit_transform(ASNData)
    ASNDataScaled = pd.DataFrame(ASNDataScaled, columns=ASNNames)
    return ASNDataScaled


def compute_CorASNData(ASNData):
    ASNDataScaled = compute_ASNDataScaled(ASNData)
    CorASNData = ASNDataScaled.corr(method='pearson')
    return CorASNData


def linear_fit(X_train, Y_train):
    # Linear Regression
    LModel = LinearRegression()
    LModel.fit(X_train, Y_train)
    return LModel


def linear_predict(LModel, X):
    Y_predLM = LModel.predict(X)
    return Y_predLM


def linear_compare(LModel, X_test, Y_test):
    Y_predLM = linear_predict(LModel, X_test)
    MseLM = mean_squared_error(Y_test, Y_predLM)
    print('Linear Regression Model')
    print(MseLM)
    return MseLM


def split_data(ASNData):
    ASNDataScaled = compute_ASNDataScaled(ASNData)
    X = ASNDataScaled.drop('SSP', axis=1)
    print('X shape = ', X.shape)

    Y = ASNDataScaled['SSP']
    print('Y shape = ', Y.shape)

    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.30, random_state=5)

    print('X train shape = ', X_train.shape)
    print('X test shape = ', X_test.shape)
    print('Y train shape = ', Y_train.shape)
    print('Y test shape = ', Y_test.shape)

    return X_train, X_test, Y_train, Y_test


def mlp_fit(X_train, Y_train):
    # MLP Regressor Model
    MLPRegModel = MLPRegressor(
        hidden_layer_sizes=(50),
        activation='relu',
        solver='lbfgs',
        tol=1e-4,
        max_iter=10000,
        random_state=1
    )
    MLPRegModel.fit(X_train, Y_train)
    return MLPRegModel


def mlp_predict(MLPRegModel, X):
    Y_predMLPReg = MLPRegModel.predict(X)
    return Y_predMLPReg


def mlp_compare(MLPRegModel, X, Y_test):
    Y_predMLPReg = mlp_predict(MLPRegModel, X)
    MseMLP = mean_squared_error(Y_test, Y_predMLPReg)
    print('SKLearn Neural Network Model')
    print(MseMLP)


def asn(ASNData):
    BasicStats = ASNData.describe()
    BasicStats = BasicStats.transpose()
    print(BasicStats)

    ScalerObject = MinMaxScaler()
    ScalerObject.fit(ASNData)
    print(ScalerObject)
    ASNDataScaled = ScalerObject.transform(ASNData)
    ASNDataScaled = pd.DataFrame(ASNDataScaled, columns=ASNNames)

    summary = ASNDataScaled.describe()
    summary = summary.transpose()
    print(summary)

    CorASNData = ASNDataScaled.corr(method='pearson')
    with pd.option_context('display.max_rows', None, 'display.max_columns', CorASNData.shape[1]):
        print(CorASNData)


def plot_ASNNames(ASNDataScaled):
    boxplot = ASNDataScaled.boxplot(column=ASNNames)
    plt.show()


def plot_CorASNData(CorASNData):
    plt.matshow(CorASNData)
    plt.xticks(range(len(CorASNData.columns)), CorASNData.columns)
    plt.yticks(range(len(CorASNData.columns)), CorASNData.columns)
    plt.colorbar()
    plt.show()


def plot_comparison_diagram(Y_test, Y_predMLPReg, Y_predLM):
    # Plot a comparison diagram
    plt.figure(1)
    plt.subplot(121)
    plt.scatter(Y_test, Y_predMLPReg)
    plt.plot((0, 1), "r--")
    plt.xlabel("Actual values")
    plt.ylabel("Predicted values")
    plt.title("SKLearn Neural Network Model")

    plt.subplot(122)
    plt.scatter(Y_test, Y_predLM)
    plt.plot((0, 1), "r--")
    plt.xlabel("Actual values")
    plt.ylabel("Predicted values")
    plt.title("SKLearn Linear Regression Model")
    plt.show()


def main():
    ASNData = read_ASNData()
    asn(ASNData)
    X_train, X_test, Y_train, Y_test = split_data(ASNData)

    lr = linear_fit(X_train, Y_train)
    Y_predLM = linear_predict(lr, X_test)

    mlp = mlp_fit(X_train, Y_train)
    Y_predMLPReg = mlp_predict(mlp, X_test)

    plot_ASNNames(compute_ASNDataScaled(ASNData))
    plot_CorASNData(compute_CorASNData(ASNData))
    plot_comparison_diagram(Y_test, Y_predMLPReg, Y_predLM)


if __name__ == "__main__":
    main()
